<!--yml
category: 未分类
date: 0001-01-01 00:00:00
--->

# Elasticsearch对于大数据量（上亿量级）的聚合如何实现？

> 原文：[https://zwmst.com/1638.html](https://zwmst.com/1638.html)

   [ *Elasticsearch* ](https://zwmst.com/elasticsearch)*[ <time datetime="2021-08-15T15:59:18+08:00"> 2021-08-15 </time> ](https://zwmst.com/1638.html)  Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的 distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，

然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来 控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配 置的精确度相关 。*