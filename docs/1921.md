<!--yml
category: 未分类
date: 0001-01-01 00:00:00
--->

# 568.Task

> 原文：[https://zwmst.com/4243.html](https://zwmst.com/4243.html)

   [ *分布式* ](https://zwmst.com/%e5%88%86%e5%b8%83%e5%bc%8f)*[ <time datetime="2021-09-28T00:28:58+08:00"> 2021-09-27 </time> ](https://zwmst.com/4243.html)  Task 分为 Map Task 和 Reduce Task 两种， 均由 TaskTracker 启动。 HDFS 以固定大小的 block 为基本单位存储数据， 而对于 MapReduce 而言， 其处理单位是 split。split 与 block 的对应关系如图所示。 split 是一个逻辑概念， 它只包含一些元数据信息， 比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定。 但需要注意的是，split 的多少决定了 Map Task 的数目 ，因为每个 split 会交由一个 Map Task 处理。

Map Task 执行过程如图所示。 由该图可知，Map Task 先将对应的 split 迭代解析成一个个key/value 对，依次调用用户自定义的 map() 函数进行处理，最终将临时结果存放到本地磁盘上，其中临时数据被分成若干个 partition，每个 partition 将被一个 Reduce Task 处理。

![](img/6ea69b2e708a5f9ed635d41a1b09d140.png)*