<!--yml
category: 未分类
date: 0001-01-01 00:00:00
-->

# 超大分页怎么处理?

> 原文：[https://zwmst.com/699.html](https://zwmst.com/699.html)

   [ *MySQL* ](https://zwmst.com/mysql)*[ <time datetime="2021-08-14T07:56:11+08:00"> 2021-08-13 </time> ](https://zwmst.com/699.html)  超大的分页一般从两个方向上来解决.

*   数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于select *from table where age > 20 limit 1000000,10这种查询其实也是有可以优化的余地 的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们 可以修改为select* from table where id in (select id from table where age > 20 limit 1000000,10).这样虽然也load了一百万的数据,但是由于索 引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以 select * from table where id > 1000000 limit 10,效率也是不错的,优化的 可能性有许多种,但是核心思想都一样,就是减少load的数据.
*   从需求的角度减少这种请求….主要是不做类似的需求(直接跳转到几百万页之后的具体某 一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续 被人恶意攻击.

解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接 返回即可.

在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种。

![image-20210813175148457](img/a8fcfd511c61758da797f2f695e461f1.png)*