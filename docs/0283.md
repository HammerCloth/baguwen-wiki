<!--yml
category: 未分类
date: 0001-01-01 00:00:00
--->

# 为什么Kafka不支持读写分离？

> 原文：[https://zwmst.com/510.html](https://zwmst.com/510.html)

   [ *Kafka* ](https://zwmst.com/kafka)*[ <time datetime="2021-08-14T06:58:33+08:00"> 2021-08-13 </time> ](https://zwmst.com/510.html)  在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而 实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明显的缺点:

(1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口 会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后 将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的A数据 的值并不为最新的 Y，由此便产生了数据不一致的问题。

(2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网 络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。*