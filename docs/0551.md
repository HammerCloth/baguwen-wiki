<!--yml
category: 未分类
date: 0001-01-01 00:00:00
-->

# 消息队列积压怎么办

> 原文：[https://zwmst.com/1088.html](https://zwmst.com/1088.html)

   [ *消息队列* ](https://zwmst.com/%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97)*[ <time datetime="2021-08-15T10:24:06+08:00"> 2021-08-15 </time> ](https://zwmst.com/1088.html)  当消费者出现异常，很容易引起队列积压，如果一秒钟1000个消息，那么一个小时就是几千万 的消息积压，是非常可怕的事情，但是生产线上又有可能会出现； 当消息积压来不及处理，rabbitMQ如果设置了消息过期时间，那么就有可能由于积压无法及 时处理而过期，这消息就被丢失了； 解决方法如下：

> 不建议在生产环境使用数据过期策略，一是数据是否丢失无法控制，二是一旦积压就很有可能丢失；建议数据的处理都有代码来控制；
> 
> 当出现消息积压时，做法就是临时扩大consumer个数,让消息快速消费,一般都 是通过业务逻辑的手段来完成如下:

rabbitmq解决积压范例

1.  修复consumer代码故隙，确保consumer逻辑正确可以消费

2.  停止consumer，开启10倍20倍的queue个数

*   创建一个临时的consumer程序，消费积压的queue，并把消息写入到扩建10倍的queue中
*   再开启10倍20倍的consumer对新的扩充后队列进行消费
*   这种做法相当于通过物理资源扩充了10们来快速消费

3.  当消费完成后，需要恢复原有架构，开启原来的consumer进行正常消费

kafka解决范例

1.  修复consumer代码故障，确保consumer逻辑正确可以消费
2.  停止consumer，新建topic，新建10倍20倍的partition个数

*   创建对应原topic的partition个数的临时的consumer程序，消费原来的topic，并把消息写入到扩建的新topic中
*   再开启对应新partition个数的consumer对新的topic进行消费
*   这种做法相当于通过物理资源扩充了10倍来快速消费*