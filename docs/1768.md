<!--yml
category: 未分类
date: 0001-01-01 00:00:00
--->

# 415.虚拟节点（down 机多节点托管）

> 原文：[https://zwmst.com/3880.html](https://zwmst.com/3880.html)

   [ *Cassandra* ](https://zwmst.com/cassandra)*[ <time datetime="2021-09-24T14:25:25+08:00"> 2021-09-24 </time> ](https://zwmst.com/3880.html)  由于这种方式会造成数据分布不均的问题，**在 Cassandra1.2 以后采用了虚拟节点的思想：不需要为每个节点分配 token，把圆环分成更多部分，让每个节点负责多个部分的数据，这样一个节点移除后，它所负责的多个 token 会托管给多个节点处理，这种思想解决了数据分布不均的问题。**![](img/0eb331d96687f7827d8ee6f4e97c353b.png)
如图所示，上面部分是标准一致性哈希，每个节点负责圆环中连续的一段，如果 Node2 突然down 掉，Node2 负责的数据托管给 Node1，即 Node1 负责 EFAB 四段，如果 Node1 里面有很多热点用户产生的数据导致 Node1 已经有点撑不住了，恰巧 B 也是热点用户产生的数据，这样一来 Node1 可能会接着 down 机，Node1down 机，Node6 还 hold 住吗？

**下面部分是虚拟节点实现，每个节点不再负责连续部分，且圆环被分为更多的部分。如果 Node2突然 down 掉，Node2 负责的数据不全是托管给 Node1，而是托管给多个节点。而且也保持了一致性哈希的特点。***