<!--yml
category: 未分类
date: 0001-01-01 00:00:00
--->

# 1219.上千万条消息在mq中积压了⼏个⼩时还没解决

> 原文：[https://zwmst.com/5743.html](https://zwmst.com/5743.html)

   [ *RabbitMQ* ](https://zwmst.com/rabbitmq)*[ <time datetime="2021-10-31T05:34:40+08:00"> 2021-10-30 </time> ](https://zwmst.com/5743.html)  1.  先修复consumer的问题，确保其恢复消费速度，然后将现有consumer都停掉；
2.  新建⼀个topic，partition是原来的10倍，临时建⽴好原先10倍或者20倍的queue数量；
3.  然后写⼀个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据；消费之后不做耗时的处理，直接均匀轮询写⼊临时建⽴好的10倍数量的queue；
4.  接着临时征⽤10倍的机器来部署consumer，每⼀批consumer消费⼀个临时queue的数据；
5.  这种做法相当于是临时将queue资源和consumer资源扩⼤10倍，以正常的10倍速度来消费数据；
6.  等快速消费完积压数据之后，得恢复原先部署架构，重新⽤原先的consumer机器来消费消息。

## 总结：

1.  修复并停掉consumer；
2.  新建⼀个topic，partition是原来的10倍，建⽴临时queue，数量是原来的10倍或20倍；
3.  写临时consumer程序，临时征⽤10倍的机器去消费数据；
4.  消费完成之后，恢复原先consumer；*